{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import cv2\n",
    "\n",
    "from pyo import *\n",
    "from music21 import pitch\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert frequencies into legible notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_to_note(freq):\n",
    "    p = pitch.Pitch()\n",
    "    p.frequency= freq\n",
    "    return p.nameWithOctave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of the reading gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"gesture_recognizer.task\"\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "GestureRecognizer = vision.GestureRecognizer\n",
    "GestureRecognizerOptions = vision.GestureRecognizerOptions\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "options = GestureRecognizerOptions(\n",
    "    base_options=BaseOptions(model_asset_buffer = open(model_path, \"rb\").read()),\n",
    "    running_mode=VisionRunningMode.IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialization of the library that will play the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pyo\n",
    "s = Server().boot()\n",
    "s.setOutputDevice(3)\n",
    "s.start()\n",
    "\n",
    "# Create Pyo objects for sound synthesis\n",
    "# base tone to be played\n",
    "oscillator = Sine()\n",
    "# vibrato wave\n",
    "vibrato = Sine(freq=5, mul=1)\n",
    "# tone with vibrato used as input\n",
    "osc_with_vibrato = oscillator * vibrato\n",
    "# ditorsion output\n",
    "disto = Disto(osc_with_vibrato,drive=0.75, slope=0.5, mul=1, add=1)\n",
    "# no distorsion output\n",
    "noDisto = oscillator * vibrato\n",
    "Disto_bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inicialization of the hand pose points detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videocapture loop\n",
    "press escape to exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with GestureRecognizer.create_from_options(options) as recognizer:\n",
    "    try:\n",
    "        while True:\n",
    "            data, image = cap.read()\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "            #processes the frame to look for hands and their position\n",
    "            results = hands.process(image)\n",
    "            if results.multi_hand_landmarks:\n",
    "                # if there are hands on the image read the gesture being made\n",
    "                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB,data=image)\n",
    "                gesture_recognition_result = recognizer.recognize(mp_image)\n",
    "                \n",
    "                if(gesture_recognition_result.gestures):\n",
    "                    for gesture in gesture_recognition_result.gestures:\n",
    "                        #set the output to be played depending on the hand gestures\n",
    "                        if gesture[0].category_name == 'Closed_Fist':\n",
    "                            Disto_bool = True\n",
    "                        elif gesture[0].category_name == 'Open_Palm':\n",
    "                            Disto_bool = False\n",
    "                    \n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    # draws the hands points position and the lines connecting them\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mphands.HAND_CONNECTIONS,\n",
    "                        mp.solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    )\n",
    "                    # extract both index and thumb positions\n",
    "                    indexFinger = hand_landmarks.landmark[8]\n",
    "                    thumbFinger = hand_landmarks.landmark[4]\n",
    "                    x_index, y_index = int(indexFinger.x * image.shape[1]), int(indexFinger.y * image.shape[0])\n",
    "                    x_thumb, y_thumb = int(thumbFinger.x * image.shape[1]), int(thumbFinger.y * image.shape[0])\n",
    "\n",
    "                    # gets the thumb to index x distance and adapts the result to be used later\n",
    "                    thumb_distance = sqrt(abs((x_index-x_thumb)**2))\n",
    "                    thumb_distance = thumb_distance/image.shape[1] * 8\n",
    "                    if x_index > image.shape[0]/2 and x_thumb > image.shape[0]/2:\n",
    "                        # if the hand is on the right side the index position will update the tone\n",
    "                        # the distance between index and thumb will increase vibrato rate on the tone\n",
    "                        oscillator.freq=y_index+100\n",
    "                        vibrato.setFreq(thumb_distance)\n",
    "                    else: \n",
    "                        # left hand's index finger will update the volume\n",
    "                        oscillator.setMul(y_index/image.shape[1] * 10 + 1)\n",
    "\n",
    "                    #displays note played and if there is distorssion or not\n",
    "                    cv2.putText(image,frequency_to_note(oscillator.freq),(10,40),cv2.FONT_HERSHEY_PLAIN,fontScale=1.2,color=(255,255,0),thickness=2)\n",
    "                    if Disto_bool:\n",
    "                        cv2.putText(image,'Distorsion On',(10,60),cv2.FONT_HERSHEY_PLAIN,fontScale=1.2,color=(255,255,0),thickness=2)\n",
    "            else:\n",
    "                #if there are no hands on the image stop playing\n",
    "                oscillator.setFreq(0)\n",
    "\n",
    "            #Control if distorsion is to be played or not    \n",
    "            if Disto_bool:\n",
    "                disto.play()\n",
    "                disto.out()\n",
    "                noDisto.stop()\n",
    "            else:\n",
    "                noDisto.play()\n",
    "                noDisto.out()\n",
    "                disto.stop()\n",
    "\n",
    "            cv2.imshow('Theremin', image)\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Stop the Pyo server when the program ends\n",
    "        s.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
